# Flutter Llama - Quick Start

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

–î–æ–±–∞–≤—å—Ç–µ –≤ `pubspec.yaml`:

```yaml
dependencies:
  flutter_llama:
    path: ../flutter_llama
```

–ó–∞—Ç–µ–º:

```bash
flutter pub get
```

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä

–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å **braindler** –æ—Ç [Ollama](https://ollama.com/nativemind/braindler):

```dart
import 'package:flutter_llama/flutter_llama.dart';

// 1. –ü–æ–ª—É—á–∏—Ç—å instance
final llama = FlutterLlama.instance;

// 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å braindler (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º q4_k_s - 88MB)
final config = LlamaConfig(
  modelPath: '/path/to/braindler-q4_k_s.gguf',  // braindler –æ—Ç ollama.com/nativemind/braindler
  nThreads: 4,
  nGpuLayers: -1,  // -1 = –≤—Å–µ —Å–ª–æ–∏ –Ω–∞ GPU
  contextSize: 2048,
);

final success = await llama.loadModel(config);

// 3. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç
if (success) {
  final params = GenerationParams(
    prompt: 'Hello, AI!',
    temperature: 0.8,
    maxTokens: 512,
  );
  
  final response = await llama.generate(params);
  print(response.text);
  print('${response.tokensPerSecond} tokens/sec');
}

// 4. –í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
await llama.unloadModel();
```

### –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

```dart
await for (final token in llama.generateStream(params)) {
  print(token); // –ö–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
}
```

## üì± –ü—Ä–∏–º–µ—Ä—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### mahamantra

```dart
import 'package:flutter_llama/flutter_llama.dart';

class LocalAIService {
  final FlutterLlama _llama = FlutterLlama.instance;
  
  Future<bool> initialize() async {
    final config = LlamaConfig(
      modelPath: await _getModelPath(),
      nThreads: 8,
      nGpuLayers: -1,
      contextSize: 4096,
    );
    
    return await _llama.loadModel(config);
  }
  
  Future<String?> askQuestion(String question) async {
    final params = GenerationParams(
      prompt: _buildPrompt(question),
      temperature: 0.8,
      maxTokens: 512,
    );
    
    final response = await _llama.generate(params);
    return response.text;
  }
}
```

### flutter_–º–æ–∑–≥–∞—á

```dart
import 'package:flutter_llama/flutter_llama.dart';

class LlamaProvider extends ChangeNotifier {
  final FlutterLlama _llama = FlutterLlama.instance;
  
  Future<bool> loadModel(String modelPath) async {
    final config = LlamaConfig(
      modelPath: modelPath,
      nThreads: 4,
      nGpuLayers: -1,
      contextSize: 4096,
    );
    
    return await _llama.loadModel(config);
  }
  
  Future<void> sendMessage(String text) async {
    final params = GenerationParams(
      prompt: _buildPromptWithContext(text),
      temperature: 0.8,
      maxTokens: 512,
    );
    
    final response = await _llama.generate(params);
    // –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞...
  }
}
```

## üéõÔ∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### –î–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤

```dart
final config = LlamaConfig(
  modelPath: modelPath,
  nThreads: 4,           // 4-6 –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö
  nGpuLayers: -1,        // –í—Å–µ —Å–ª–æ–∏ –Ω–∞ GPU
  contextSize: 2048,     // 2048 –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
  batchSize: 512,
  useGpu: true,
);
```

### –î–ª—è –º–æ—â–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤

```dart
final config = LlamaConfig(
  modelPath: modelPath,
  nThreads: 8,           // 6-8 –¥–ª—è –º–æ—â–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
  nGpuLayers: -1,
  contextSize: 4096,     // –ë–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç
  batchSize: 512,
  useGpu: true,
);
```

### –î–ª—è —Å–ª–∞–±—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤

```dart
final config = LlamaConfig(
  modelPath: modelPath,
  nThreads: 2,           // –ú–µ–Ω—å—à–µ –ø–æ—Ç–æ–∫–æ–≤
  nGpuLayers: 0,         // –¢–æ–ª—å–∫–æ CPU
  contextSize: 1024,     // –ú–µ–Ω—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç
  batchSize: 256,
  useGpu: false,
);
```

## üîß –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: Braindler –æ—Ç Ollama

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª—å [braindler](https://ollama.com/nativemind/braindler) - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤:

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏:**

- **braindler:q2_k** (72MB): –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä, –±—ã—Å—Ç—Ä–æ, —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- **braindler:q4_k_s** (88MB): ‚≠ê **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è** - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
- **braindler:q5_k_m** (103MB): –í—ã—à–µ –∫–∞—á–µ—Å—Ç–≤–æ, –±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—Ä
- **braindler:q8_0** (140MB): –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- **braindler:f16** (256MB): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ

**–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å:**

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama —Å https://ollama.com
# 2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å
ollama pull nativemind/braindler:q4_k_s

# 3. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –≤ GGUF (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
ollama export nativemind/braindler:q4_k_s -o braindler-q4_k_s.gguf
```

### –ü—Ä–∏–º–µ—Ä –ø—É—Ç–µ–π –∫ –º–æ–¥–µ–ª—è–º

```dart
// Android
'/data/user/0/your.package/app_flutter/models/braindler-q4_k_s.gguf'

// iOS
'/var/mobile/Containers/Data/Application/UUID/Documents/models/braindler-q4_k_s.gguf'
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```dart
final response = await llama.generate(params);

print('–¢–µ–∫—Å—Ç: ${response.text}');
print('–¢–æ–∫–µ–Ω–æ–≤: ${response.tokensGenerated}');
print('–í—Ä–µ–º—è: ${response.generationTimeMs}–º—Å');
print('–°–∫–æ—Ä–æ—Å—Ç—å: ${response.tokensPerSecond.toStringAsFixed(2)} tok/s');
```

## üêõ Troubleshooting

### –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è

```dart
// –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
final file = File(modelPath);
if (!file.existsSync()) {
  print('–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: $modelPath');
}

// –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
print('–†–∞–∑–º–µ—Ä: ${file.lengthSync()} –±–∞–π—Ç');
```

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

1. –£–≤–µ–ª–∏—á—å—Ç–µ `nGpuLayers` –¥–æ `-1`
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é (Q2_K, Q4_K)
3. –£–º–µ–Ω—å—à–∏—Ç–µ `contextSize`
4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ `useGpu: true`

### Out of memory

1. –£–º–µ–Ω—å—à–∏—Ç–µ `contextSize`
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é
3. –£–º–µ–Ω—å—à–∏—Ç–µ `nThreads`
4. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `nGpuLayers: 0` (—Ç–æ–ª—å–∫–æ CPU)

## üìö –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [README.md](README.md) - –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [INTEGRATION_GUIDE.md](INTEGRATION_GUIDE.md) - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
- [example/](example/) - –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

## üÜò –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –ø—Ä–æ–±–ª–µ–º –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫:
- README.md
- INTEGRATION_GUIDE.md
- GitHub Issues

---

**Happy coding! üöÄ**

